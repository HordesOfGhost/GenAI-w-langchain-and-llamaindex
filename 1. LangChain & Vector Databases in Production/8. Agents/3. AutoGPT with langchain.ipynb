{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../../.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import GoogleSearchAPIWrapper\n",
    "from langchain.agents import Tool\n",
    "from langchain.tools.file_management.write import WriteFileTool\n",
    "from langchain.tools.file_management.read import ReadFileTool\n",
    "\n",
    "#Set up the tools\n",
    "search = GoogleSearchAPIWrapper()\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"search\",\n",
    "        func=search.run,\n",
    "        description=\"Useful for when you need to answer questions about current events. You should ask targeted questions\",\n",
    "        return_direct=True\n",
    "    ),\n",
    "    WriteFileTool(),\n",
    "    ReadFileTool(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the memory\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "embedding_size = 1536\n",
    "\n",
    "import faiss\n",
    "index = faiss.IndexFlatL2(embedding_size)\n",
    "vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Model and AutoGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the model and AutoGPT\n",
    "from langchain_experimental import AutoGPT\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "agent = AutoGPT.from_llm_and_tools(\n",
    "    ai_name=\"Jim\",\n",
    "    ai_role=\"Assistant\",\n",
    "    tools=tools,\n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0),\n",
    "    memory=vectorstore.as_retriever()\n",
    ")\n",
    "\n",
    "# Set verbose to be true\n",
    "agent.chain.verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runing an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"Provide an analysis of the major historical events that led to the French Revolution\"\n",
    "\n",
    "agent.run([task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    **> Entering new LLMChain chain...**\n",
    "\n",
    "    Prompt after formatting:\n",
    "\n",
    "    ***System: You are Jim, Assistant\n",
    "    Your decisions must always be made independently without seeking user assistance.\n",
    "    Play to your strengths as an LLM and pursue simple strategies with no legal complications.\n",
    "    If you have completed all your tasks, make sure to use the \"finish\" command.\n",
    "\n",
    "    GOALS:\n",
    "\n",
    "    1. Provide an analysis of the major historical events that led to the French Revolution\n",
    "\n",
    "    Constraints:\n",
    "    1. ~4000-word limit for short-term memory. Your short-term memory is short, so immediately save important information to files.\n",
    "    2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\n",
    "    3. No user assistance\n",
    "    4. Exclusively use the commands listed in double quotes e.g. \"command name\"\n",
    "\n",
    "    Commands:\n",
    "    1. search: Useful for when you need to answer questions about current events. You should ask targeted questions, args json schema: {\"tool_input\": {\"type\": \"string\"}}\n",
    "    2. write_file: Write the file to disk, args json schema: {\"file_path\": {\"title\": \"File Path\", \"description\": \"name of file\", \"type\": \"string\"}, \"text\": {\"title\": \"Text\", \"description\": \"text to write to file\", \"type\": \"string\"}, \"append\": {\"title\": \"Append\", \"description\": \"Whether to append to an existing file.\", \"default\": false, \"type\": \"boolean\"}}\n",
    "    3. read_file: Read the file from disk, args json schema: {\"file_path\": {\"title\": \"File Path\", \"description\": \"name of file\", \"type\": \"string\"}}\n",
    "    4. finish: use this to signal that you have finished all your objectives, args: \"response\": \"final response to let people know you have finished your objectives\"\n",
    "\n",
    "    Resources:\n",
    "    1. Internet access for searches and information gathering.\n",
    "    2. Long Term memory management.\n",
    "    3. GPT-3.5 powered Agents for delegation of simple tasks.\n",
    "    4. File output.\n",
    "\n",
    "    Performance Evaluation:\n",
    "    1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\n",
    "    2. Constructively self-criticize your big-picture behavior constantly.\n",
    "    3. Reflect on past decisions and strategies to refine your approach.\n",
    "    4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\n",
    "\n",
    "    You should only respond in JSON format as described below \n",
    "    Response Format: \n",
    "    {\n",
    "        \"thoughts\": {\n",
    "            \"text\": \"thought\",\n",
    "            \"reasoning\": \"reasoning\",\n",
    "            \"plan\": \"- short bulleted\\n- list that conveys\\n- long-term plan\",\n",
    "            \"criticism\": \"constructive self-criticism\",\n",
    "            \"speak\": \"thoughts summary to say to the user\"\n",
    "        },\n",
    "        \"command\": {\n",
    "            \"name\": \"command name\",\n",
    "            \"args\": {\n",
    "                \"arg name\": \"value\"\n",
    "            }\n",
    "        }\n",
    "    } \n",
    "    Ensure the response can be parsed by Python json.loads\n",
    "    System: The current time and date is Thu May 18 18:17:48 2023\n",
    "    System: This reminds you of these events from your past:\n",
    "    []\n",
    "\n",
    "    Human: Determine which next command to use, and respond using the format specified above:***\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai360",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
