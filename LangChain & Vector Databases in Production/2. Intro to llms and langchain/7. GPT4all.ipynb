{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT4ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import LlamaCpp\n",
    "from langchain import HuggingFaceHub, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_for_all = LlamaCpp(model_path=\"D:/gpt4all/orca-mini-3b-gguf2-q4_0.gguf\",temperature=0.75,\n",
    "    max_tokens=2000,\n",
    "    top_p=1,\n",
    "    verbose=False,  # Verbose is required to pass to the callback manager\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain import PromptTemplate, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Water droplets form on the surface of the earth.\n",
      "2. The water droplets combine and become bigger drops.\n",
      "3. As the drops fall to the ground, they form clouds.\n",
      "4. When the clouds become heavy with water, they release heat and rain begins to fall.\n",
      "5. The rain can be light or heavy depending on the amount of moisture in the air.\n",
      "6. Some areas may experience flooding due to heavy rainfall.\n",
      "7. The rain can be stopped by rain gauges or other devices that measure rainfall.\n"
     ]
    }
   ],
   "source": [
    "question = \"What happens when it rains somewhere? Answer: Let's think step by step. \"\n",
    "# using local llm\n",
    "print(llm_for_all.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai360",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
