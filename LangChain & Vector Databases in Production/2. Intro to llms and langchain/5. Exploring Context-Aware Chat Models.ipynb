{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../../.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work On Mistral Instruct v2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ghost\\anaconda3\\envs\\genai360\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "WARNING! repo_id is not default parameter.\n",
      "                    repo_id was transferred to model_kwargs.\n",
      "                    Please confirm that repo_id is what you intended.\n",
      "WARNING! task is not default parameter.\n",
      "                    task was transferred to model_kwargs.\n",
      "                    Please confirm that task is what you intended.\n",
      "WARNING! huggingfacehub_api_token is not default parameter.\n",
      "                    huggingfacehub_api_token was transferred to model_kwargs.\n",
      "                    Please confirm that huggingfacehub_api_token is what you intended.\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
    "from langchain_core.messages import HumanMessage,SystemMessage,AIMessage\n",
    "\n",
    "# initialize Hub LLM\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id='mistralai/Mistral-7B-Instruct-v0.2',\n",
    "    model_kwargs={'temperature':0.5,\"max_length\": 64,\"max_new_tokens\":512}\n",
    ")\n",
    "\n",
    "# instialize chat LLM\n",
    "chat_llm = ChatHuggingFace(llm = llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    HumanMessage(content=\"You are a helpful assistant.\",role=\"user\"),\n",
    "    AIMessage(content=\"Yes I am.\",role=\"assistant\"),\n",
    "    HumanMessage(content=\"What is the capital of France?\",role=\"user\"),\n",
    "    AIMessage(content=\"The capital of France is Paris.\",role=\"assistant\"),\n",
    "    HumanMessage(content=\"Thank You\",role=\"user\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] You are a helpful assistant. [/INST]Yes I am.</s>[INST] What is the capital of France? [/INST]The capital of France is Paris.</s>[INST] Thank You [/INST]You're welcome! Is there anything else I can help you with? I'm here to answer any question you might have. Just let me know. Have a great day! :)\n"
     ]
    }
   ],
   "source": [
    "chat_llm._to_chat_prompt(messages)\n",
    "res = chat_llm.invoke(messages)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test If it remembered previous dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [\n",
    "    AIMessage(\"Anything you want to talk about?\",role=\"assistant\"),\n",
    "    HumanMessage(content=\"I'd like to know more about the city you just mentioned.\",role=\"user\")]\n",
    "# add to messages\n",
    "messages.extend(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] You are a helpful assistant. [/INST]Yes I am.</s>[INST] What is the capital of France? [/INST]The capital of France is Paris.</s>[INST] Thank You [/INST]Anything you want to talk about?</s>[INST] I'd like to know more about the city you just mentioned. [/INST]Paris is the capital and most populous city of France, with an estimated population of 10.5 million people in the metropolitan area. It is located in the northern part of France, in the region of Île-de-France, and is considered one of the world's leading business and cultural centers. Paris is known for its museums and art galleries, beautiful gardens, historic sites, and fashion industry. Some of the most famous landmarks in Paris include the Eiffel Tower, the Louvre Museum, Notre-Dame Cathedral, and the Champs-Élysées. Paris is also famous for its cuisine, particularly for dishes such as escargot, coq au vin, and crêpes. The city is served by two major international airports, Charles de Gaulle and Orly, and is a major European transportation hub. Paris is also known for its vibrant nightlife and is home to many world-renowned restaurants, bars, and nightclubs.\n"
     ]
    }
   ],
   "source": [
    "chat_llm._to_chat_prompt(messages)\n",
    "res = chat_llm.invoke(messages)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai360",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
