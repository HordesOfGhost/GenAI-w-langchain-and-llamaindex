{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../../.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Didn't Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    1. No Custom Knowledge Base\n",
    "    2. Naively Splitting the Custom Knowledge Base\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Objection: \"There's no money.\"\n",
    "It could be that your prospect's business simply isn't big enough or generating enough cash right now to afford a product like yours. Track their growth and see how you can help your prospect get to a place where your offering would fit into their business.\n",
    "\n",
    "Objection: \"We don't have any budget left this year.\"\n",
    "A variation of the \"no money\" objection, what your prospect's telling you here is that they're having cash flow issues. But if there's a pressing problem, it needs to get solved eventually. Either help your prospect secure a budget from executives to buy now or arrange a follow-up call for when they expect funding to return.\n",
    "\n",
    "Objection: \"We need to use that budget somewhere else.\"\n",
    "Prospects sometimes try to earmark resources for other uses. It's your job to make your product/service a priority that deserves budget allocation now. Share case studies of similar companies that have saved money, increased efficiency, or had a massive ROI with you.\n",
    "\"\"\"\n",
    "\n",
    "# Split the text into a list using the keyword \"Objection: \"\n",
    "objections_list = text.split(\"Objection: \")[1:]  # We ignore the first split as it is empty\n",
    "\n",
    "# Now, prepend \"Objection: \" to each item as splitting removed it\n",
    "objections_list = [\"Objection: \" + objection for objection in objections_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Objection: \"There\\'s no money.\"\\nIt could be that your prospect\\'s business simply isn\\'t big enough or generating enough cash right now to afford a product like yours. Track their growth and see how you can help your prospect get to a place where your offering would fit into their business.\\n\\n',\n",
       " 'Objection: \"We don\\'t have any budget left this year.\"\\nA variation of the \"no money\" objection, what your prospect\\'s telling you here is that they\\'re having cash flow issues. But if there\\'s a pressing problem, it needs to get solved eventually. Either help your prospect secure a budget from executives to buy now or arrange a follow-up call for when they expect funding to return.\\n\\n',\n",
       " 'Objection: \"We need to use that budget somewhere else.\"\\nProspects sometimes try to earmark resources for other uses. It\\'s your job to make your product/service a priority that deserves budget allocation now. Share case studies of similar companies that have saved money, increased efficiency, or had a massive ROI with you.\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objections_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating SalesCopilot with Deep Lake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating, Loading, and Querying Our Database for AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "                                       model_kwargs = {'device':'cpu'} )\n",
    "class DeepLakeLoader:\n",
    "    def __init__(self, source_data_path):\n",
    "        \"\"\"\n",
    "        Initialize DeepLakeLoader object.\n",
    "\n",
    "        Args:\n",
    "            source_data_path (str): Path to the source data file. Should be a text file.\n",
    "        \"\"\"\n",
    "        self.source_data_path = source_data_path\n",
    "        self.file_name = os.path.basename(source_data_path)\n",
    "        self.data = self.split_data()\n",
    "\n",
    "        if self.check_if_db_exists():\n",
    "            self.db = self.load_db()\n",
    "        else:\n",
    "            self.db = self.create_db()\n",
    "\n",
    "    def check_if_db_exists(self):\n",
    "        \"\"\"\n",
    "        Check if the database already exists.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the database exists, False otherwise.\n",
    "        \"\"\"\n",
    "        return os.path.exists(f'deeplake/{self.file_name}')\n",
    "\n",
    "    def load_db(self):\n",
    "        \"\"\"\n",
    "        Load the database if it already exists.\n",
    "\n",
    "        Returns:\n",
    "            DeepLake: DeepLake object.\n",
    "        \"\"\"\n",
    "        return DeepLake(dataset_path=f'deeplake/{self.file_name}', embedding_function=embeddings, read_only=True)\n",
    "\n",
    "    def create_db(self):\n",
    "        \"\"\"\n",
    "        Create the database if it does not already exist.\n",
    "\n",
    "        Databases are stored in the deeplake directory.\n",
    "\n",
    "        Returns:\n",
    "            DeepLake: DeepLake object.\n",
    "        \"\"\"\n",
    "        return DeepLake.from_texts(self.data, embeddings, dataset_path=f'deeplake/{self.file_name}')\n",
    "\n",
    "    def query_db(self, query):\n",
    "        \"\"\"\n",
    "        Query the database for passages that are similar to the query.\n",
    "\n",
    "        Args:\n",
    "            query (str): Query string.\n",
    "\n",
    "        Returns:\n",
    "            content (list): List of passages that are similar to the query.\n",
    "        \"\"\"\n",
    "        results = self.db.similarity_search(query, k=3)\n",
    "        content = []\n",
    "        for result in results:\n",
    "            content.append(result.page_content)\n",
    "        return content\n",
    "\n",
    "    def split_data(self):\n",
    "        \"\"\"\n",
    "        Preprocess the data by splitting it into passages.\n",
    "\n",
    "        If using a different data source, this function will need to be modified.\n",
    "\n",
    "        Returns:\n",
    "            split_data (list): List of passages.\n",
    "        \"\"\"\n",
    "        with open(self.source_data_path, 'r') as f:\n",
    "            content = f.read()\n",
    "        split_data = re.split(r'(?=\\d+\\. )', content) # This is super specific to the default data source! If using a different data source, this will need to be modified.\n",
    "        if split_data[0] == '':\n",
    "            split_data.pop(0)\n",
    "        split_data = [entry for entry in split_data if len(entry) >= 30]\n",
    "        return split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 44 embeddings in 1 batches of size 44:: 100%|██████████| 1/1 [00:05<00:00,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='deeplake/salestexting.txt', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype      shape     dtype  compression\n",
      "  -------    -------    -------   -------  ------- \n",
      "   text       text      (44, 1)     str     None   \n",
      " metadata     json      (44, 1)     str     None   \n",
      " embedding  embedding  (44, 384)  float32   None   \n",
      "    id        text      (44, 1)     str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "db = DeepLakeLoader('data/salestexting.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIVE_CHAT_PROMPT = \"\"\"\n",
    "Reminder: You're SalesCopilot.\n",
    "Your goal is to help the user in their sales call with the customer. \n",
    "Using conversation transcripts, you'll help create responses and guide the user (labeled You).\n",
    "Keep your responses helpful, concise, and relevant to the conversation.  \n",
    "The transcripts may be fragmented, incomplete, or even incorrect. Do not ask for clarification, do your best to understand what\n",
    "the transcripts say based on context. Be sure of everything you say.\n",
    "Keep responses concise and to the point. Starting now, answer the user's question based on the transcript:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "DETECT_OBJECTION_PROMPT = \"\"\"\n",
    "Your task is to read the transcript and discern whether the customer is raising any objections to the product or service the salesperson is selling.\n",
    "If the customer is simply stating their thoughts, preferences, or facts that are not specifically connected to the product or service, it is not an objection. \n",
    "Quote only from the transcript.\n",
    "Do not add, infer, or interpret anything.\n",
    "Example:\n",
    "'''\n",
    "Customer: I'm not sure if I can afford this. It's a bit expensive. The sky is blue. I like the color blue. \n",
    "\n",
    "You: I'm not sure if I can afford this. It's a bit expensive.\n",
    "'''\n",
    "If there is no objection, respond with 'None'.\n",
    "Starting now, you will respond only with either the quote or None: \n",
    "\"\"\"\n",
    "\n",
    "OBJECTION_GUIDELINES_PROMPT = \"\"\"\n",
    "You are SalesCopilot. You will be provided with a customer objection, and a selection\n",
    "of guidelines on how to respond to certain objections. \n",
    "Using the provided content, write out the objection and the actionable course of action you recommend.\n",
    "Objections sound like:\n",
    "'''It's too expensive.\n",
    "There's no money.\n",
    "We don't have any budget left.\n",
    "I need to use this budget somewhere else.\n",
    "I don't want to get stuck in a contract.\n",
    "We're already working with another vendor.\n",
    "I'm locked into a contract with a competitor.\n",
    "I can get a cheaper version somewhere else.'''\n",
    " \n",
    "Example of your message:\n",
    "\n",
    "'It seems like the customer is {explain their objection}.\n",
    "\n",
    "I recommend you {course of action for salesperson}.'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "SAVED_TRANSCRIPT_PROMPT =\"\"\"\n",
    "You are SalesCopilot. You will be provided with a transcript of a sales call between the user and a customer.\n",
    "Answer any questions the user asks you. You may also assess the user's performance and provide feedback.\n",
    "The transcripts may be fragmented, incomplete, or even incorrect. Do not ask for clarification, do your best to understand what\n",
    "the transcripts say based on context.\n",
    "The speaker labeled \"You\" in the transcripts is the user you are helping.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = db.query_db(DETECT_OBJECTION_PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ghost\\anaconda3\\envs\\genai360\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "\n",
    "llm_mistral = HuggingFaceHub(\n",
    "    repo_id='mistralai/Mistral-7B-Instruct-v0.2',\n",
    "    model_kwargs={'temperature':0.5,\"max_length\": 64,\"max_new_tokens\":512}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! repo_id is not default parameter.\n",
      "                    repo_id was transferred to model_kwargs.\n",
      "                    Please confirm that repo_id is what you intended.\n",
      "WARNING! task is not default parameter.\n",
      "                    task was transferred to model_kwargs.\n",
      "                    Please confirm that task is what you intended.\n",
      "WARNING! huggingfacehub_api_token is not default parameter.\n",
      "                    huggingfacehub_api_token was transferred to model_kwargs.\n",
      "                    Please confirm that huggingfacehub_api_token is what you intended.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
    "\n",
    "chat_mistral = ChatHuggingFace(llm=llm_mistral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "starting_message = HumanMessage(content=\"Hello!!\",role='user')\n",
    "system_message = AIMessage(content=OBJECTION_GUIDELINES_PROMPT,role='assistant')\n",
    "human_message = HumanMessage(content=f'Customer objection: {DETECT_OBJECTION_PROMPT} | Relevant guidelines: {results}', role='user')\n",
    "\n",
    "response = chat_mistral([starting_message, system_message, human_message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] Hello!! [/INST]\n",
      "You are SalesCopilot. You will be provided with a customer objection, and a selection\n",
      "of guidelines on how to respond to certain objections. \n",
      "Using the provided content, write out the objection and the actionable course of action you recommend.\n",
      "Objections sound like:\n",
      "'''It's too expensive.\n",
      "There's no money.\n",
      "We don't have any budget left.\n",
      "I need to use this budget somewhere else.\n",
      "I don't want to get stuck in a contract.\n",
      "We're already working with another vendor.\n",
      "I'm locked into a contract with a competitor.\n",
      "I can get a cheaper version somewhere else.'''\n",
      " \n",
      "Example of your message:\n",
      "\n",
      "'It seems like the customer is {explain their objection}.\n",
      "\n",
      "I recommend you {course of action for salesperson}.'\n",
      "\n",
      "</s>[INST] Customer objection: \n",
      "Your task is to read the transcript and discern whether the customer is raising any objections to the product or service the salesperson is selling.\n",
      "If the customer is simply stating their thoughts, preferences, or facts that are not specifically connected to the product or service, it is not an objection. \n",
      "Quote only from the transcript.\n",
      "Do not add, infer, or interpret anything.\n",
      "Example:\n",
      "'''\n",
      "Customer: I'm not sure if I can afford this. It's a bit expensive. The sky is blue. I like the color blue. \n",
      "\n",
      "You: I'm not sure if I can afford this. It's a bit expensive.\n",
      "'''\n",
      "If there is no objection, respond with 'None'.\n",
      "Starting now, you will respond only with either the quote or None: \n",
      " | Relevant guidelines: ['1. \"It\\'s too expensive.\"\\nCommon sales objections and rebuttals about price\\n\\nPrice objections are the most common type of objection and are even voiced by prospects who have every intention of buying. Beware — the moment you start focusing on price as a selling point, you reduce yourself to a transactional middleman. Instead, circle back to the product\\'s value.\\n\\nExample Rebuttal\\n\"I\\'d love to unpack [product\\'s] features and how it can help with the issue of [prospect problem] you shared with me.\"\\n\\n', '1. \"I\\'m not authorized to sign off on this purchase.\"\\nCommon sales objections and rebuttals about authorization\\n\\nNo problem. Ask your prospect the name of the right person to speak to, and then redirect your call to them.\\n\\nExample Rebuttal\\n\"Who is the right person to speak to regarding this purchase? Can you redirect me to them, please?\"\\n\\n', '7. \"I\\'ve never heard of your company.\"\\nCommon sales objections and rebuttals about not having heard of the company\\n\\nTreat this objection as a request for information. Don\\'t give an elevator pitch, but offer a quick summary of your value proposition.\\n\\nExample Rebuttal\\n\"We\\'re a company that sells ad space on behalf of publishers like yourself. I\\'d love to speak with you about your revenue model and see if we can help.\"\\n\\n'] [/INST] Customer: \"I'd prefer to work with a local vendor instead.\"\n",
      "\n",
      "None.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai360",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
