{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../../.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping For News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from newspaper import Article # https://github.com/codelucas/newspaper\n",
    "import time\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'\n",
    "}\n",
    "\n",
    "article_urls = [\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/16/openai-ceo-ai-regulation-is-essential/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/15/jay-migliaccio-ibm-watson-on-leveraging-ai-to-improve-productivity/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/15/iurii-milovanov-softserve-how-ai-ml-is-helping-boost-innovation-and-personalisation/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/11/ai-and-big-data-expo-north-america-begins-in-less-than-one-week/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/05/02/ai-godfather-warns-dangers-and-quits-google/\",\n",
    "    \"https://www.artificialintelligence-news.com/2023/04/28/palantir-demos-how-ai-can-used-military/\"\n",
    "]\n",
    "\n",
    "session = requests.Session()\n",
    "pages_content = [] # where we save the scraped articles\n",
    "\n",
    "for url in article_urls:\n",
    "    try:\n",
    "        time.sleep(2) # sleep two seconds for gentle scraping\n",
    "        response = session.get(url, headers=headers, timeout=10)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            article = Article(url)\n",
    "            article.download() # download HTML of webpage\n",
    "            article.parse() # parse HTML to extract the article text\n",
    "            pages_content.append({ \"url\": url, \"text\": article.text })\n",
    "        else:\n",
    "            print(f\"Failed to fetch article at {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while fetching article at {url}: {e}\")\n",
    "\n",
    "#If an error occurs while fetching an article, we catch the exception and print\n",
    "#an error message. This ensures that even if one article fails to download,\n",
    "#the rest of the articles can still be processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedd and Store in DeepLake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "\n",
    "\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2',\n",
    "                                       model_kwargs = {'device':'cpu'} )\n",
    "\n",
    "# TODO: use your organization id here. (by default, org id is your username)\n",
    "my_activeloop_org_id = \"thapabibek1129\"\n",
    "my_activeloop_dataset_name = \"langchain_course_qabot_with_source\"\n",
    "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
    "\n",
    "db = DeepLake(dataset_path=dataset_path, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "all_texts, all_metadatas = [], []\n",
    "for d in pages_content:\n",
    "    chunks = text_splitter.split_text(d[\"text\"])\n",
    "    for chunk in chunks:\n",
    "        all_texts.append(chunk)\n",
    "        all_metadatas.append({ \"source\": d[\"url\"] })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 49 embeddings in 1 batches of size 49:: 100%|██████████| 1/1 [00:36<00:00, 36.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://thapabibek1129/langchain_course_qabot_with_source', tensors=['text', 'metadata', 'embedding', 'id'])\n",
      "\n",
      "  tensor      htype      shape     dtype  compression\n",
      "  -------    -------    -------   -------  ------- \n",
      "   text       text      (49, 1)     str     None   \n",
      " metadata     json      (49, 1)     str     None   \n",
      " embedding  embedding  (49, 384)  float32   None   \n",
      "    id        text      (49, 1)     str     None   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['d08968d6-ca56-11ee-9c94-a434d9523559',\n",
       " 'd08968d7-ca56-11ee-abdd-a434d9523559',\n",
       " 'd08968d8-ca56-11ee-8cae-a434d9523559',\n",
       " 'd08968d9-ca56-11ee-9a35-a434d9523559',\n",
       " 'd08968da-ca56-11ee-8d56-a434d9523559',\n",
       " 'd08968db-ca56-11ee-a5e2-a434d9523559',\n",
       " 'd08968dc-ca56-11ee-9d32-a434d9523559',\n",
       " 'd08968dd-ca56-11ee-8cfd-a434d9523559',\n",
       " 'd08968de-ca56-11ee-bc24-a434d9523559',\n",
       " 'd08968df-ca56-11ee-88ea-a434d9523559',\n",
       " 'd08968e0-ca56-11ee-85c1-a434d9523559',\n",
       " 'd08968e1-ca56-11ee-aec7-a434d9523559',\n",
       " 'd08968e2-ca56-11ee-9c61-a434d9523559',\n",
       " 'd08968e3-ca56-11ee-9dfa-a434d9523559',\n",
       " 'd08968e4-ca56-11ee-b966-a434d9523559',\n",
       " 'd08968e5-ca56-11ee-bfab-a434d9523559',\n",
       " 'd08968e6-ca56-11ee-ad65-a434d9523559',\n",
       " 'd08968e7-ca56-11ee-9b5f-a434d9523559',\n",
       " 'd08968e8-ca56-11ee-aed2-a434d9523559',\n",
       " 'd08968e9-ca56-11ee-b930-a434d9523559',\n",
       " 'd08968ea-ca56-11ee-b24c-a434d9523559',\n",
       " 'd08968eb-ca56-11ee-abca-a434d9523559',\n",
       " 'd08968ec-ca56-11ee-b849-a434d9523559',\n",
       " 'd08968ed-ca56-11ee-9a96-a434d9523559',\n",
       " 'd0897cb9-ca56-11ee-80ae-a434d9523559',\n",
       " 'd0897e70-ca56-11ee-8a90-a434d9523559',\n",
       " 'd0897e71-ca56-11ee-9930-a434d9523559',\n",
       " 'd0897e72-ca56-11ee-a222-a434d9523559',\n",
       " 'd0897e73-ca56-11ee-a9db-a434d9523559',\n",
       " 'd0897e74-ca56-11ee-a79a-a434d9523559',\n",
       " 'd0897e75-ca56-11ee-b568-a434d9523559',\n",
       " 'd0897e76-ca56-11ee-a9f7-a434d9523559',\n",
       " 'd0897e77-ca56-11ee-8d7d-a434d9523559',\n",
       " 'd0897e78-ca56-11ee-9bb7-a434d9523559',\n",
       " 'd0897e79-ca56-11ee-a651-a434d9523559',\n",
       " 'd0897e7a-ca56-11ee-87e5-a434d9523559',\n",
       " 'd0897e7b-ca56-11ee-81ec-a434d9523559',\n",
       " 'd0897e7c-ca56-11ee-9a52-a434d9523559',\n",
       " 'd0897e7d-ca56-11ee-a93b-a434d9523559',\n",
       " 'd0897e7e-ca56-11ee-8419-a434d9523559',\n",
       " 'd0897e7f-ca56-11ee-a3a3-a434d9523559',\n",
       " 'd0897e80-ca56-11ee-b5f5-a434d9523559',\n",
       " 'd0897e81-ca56-11ee-863a-a434d9523559',\n",
       " 'd0897e82-ca56-11ee-937c-a434d9523559',\n",
       " 'd0897e83-ca56-11ee-b6d0-a434d9523559',\n",
       " 'd0897e84-ca56-11ee-8987-a434d9523559',\n",
       " 'd0897e85-ca56-11ee-81d2-a434d9523559',\n",
       " 'd0897e86-ca56-11ee-9003-a434d9523559',\n",
       " 'd0897e87-ca56-11ee-a25e-a434d9523559']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we add all the chunks to the deep lake, along with their metadata\n",
    "db.add_texts(all_texts, all_metadatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ghost\\anaconda3\\envs\\genai360\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain import HuggingFaceHub\n",
    "\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id='mistralai/Mistral-7B-Instruct-v0.2',\n",
    "    model_kwargs={'temperature':0.5,\"max_length\": 64,\"max_new_tokens\":512}\n",
    ")\n",
    "\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(llm=llm,\n",
    "                                                    chain_type=\"stuff\",\n",
    "                                                    retriever=db.as_retriever())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      " Geoffrey Hinton, known as the \"Godfather of AI,\" has expressed concerns about the potential dangers of AI, including its ability to generate false text, images, and videos, and its impact on the job market. He resigned from Google to discuss these concerns openly.\n",
      "\n",
      "Sources:\n",
      "- \n",
      "https://www.artificialintelligence-news.com/2023/05/02/ai-godfather-warns-dangers-and-quits-google/\n"
     ]
    }
   ],
   "source": [
    "d_response = chain({\"question\": \"What does Geoffrey Hinton think about recent trends in AI?\"})\n",
    "\n",
    "print(\"Response:\")\n",
    "print(d_response[\"answer\"])\n",
    "print(\"Sources:\")\n",
    "for source in d_response[\"sources\"].split(\", \"):\n",
    "    print(\"- \" + source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai360",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
