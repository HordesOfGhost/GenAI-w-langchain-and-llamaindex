{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DeepLakeVectorStore\n",
    "def create_upload_vectore_store(\n",
    "    chunked_text: list,\n",
    "    vector_store_path: Union[str, os.PathLike],\n",
    "    filename: str,\n",
    "    metadata: Optional[list[dict]] = None,\n",
    "):\n",
    "    vector_store = DeepLakeVectorStore(\n",
    "        dataset_path=vector_store_path,\n",
    "        runtime={\"tensor_db\": True},\n",
    "        overwrite=True,\n",
    "        tensor_params=[\n",
    "            {\"name\": \"text\", \"htype\": \"text\"},\n",
    "            {\"name\": \"embedding\", \"htype\": \"embedding\"},\n",
    "            {\"name\": \"filename\", \"htype\": \"text\"},\n",
    "            {\"name\": \"metadata\", \"htype\": \"json\"},\n",
    "        ],\n",
    "    )\n",
    "    vector_store = vector_store.vectorstore\n",
    "    vector_store.add(\n",
    "        text=chunked_text,\n",
    "        embedding_function=embedding_function_text,\n",
    "        filename=filename,\n",
    "        embedding_data=chunked_text,\n",
    "        rate_limiter={\n",
    "            \"enabled\": True,\n",
    "            \"bytes_per_minute\": 1500000,\n",
    "            \"batch_byte_size\": 10000,\n",
    "        },\n",
    "        metadata=metadata if metadata else None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_and_nodes_after_visual_similarity(filenames: list):\n",
    "    vector_store = load_vector_store(vector_store_path=VECTOR_STORE_PATH_DESCRIPTION)\n",
    "\n",
    "    conditions = \" or \".join(f\"filename == '{name}'\" for name in filenames)\n",
    "    tql_query = f\"select * where {conditions}\"\n",
    "\n",
    "    filtered_elements = vector_store.vectorstore.search(query=tql_query)\n",
    "    chunks = []\n",
    "    for el in filtered_elements[\"text\"]:\n",
    "        chunks.append(el)\n",
    "\n",
    "    string_iterable_reader = download_loader(\"StringIterableReader\")\n",
    "    loader = string_iterable_reader()\n",
    "    documents = loader.load_data(texts=chunks)\n",
    "    node_parser = SimpleNodeParser.from_defaults(separator=\"\\n\")\n",
    "    nodes = node_parser.get_nodes_from_documents(documents)\n",
    "\n",
    "    # To ensure same id's per run, we manually set them.\n",
    "    for idx, node in enumerate(nodes):\n",
    "        node.id_ = f\"node_{idx}\"\n",
    "\n",
    "    llm = OpenAI(model=\"gpt-4\")\n",
    "\n",
    "    service_context = ServiceContext.from_defaults(llm=llm)\n",
    "    index = VectorStoreIndex(nodes=nodes)\n",
    "    return index, nodes, service_context, filtered_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, nodes, service_context = get_index_and_nodes_from_activeloop(\n",
    "    vector_store_path=VECTOR_STORE_PATH_BASELINE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_defaults(nodes=nodes, similarity_top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_bm25_response = bm25_retriever.retrieve(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicRetrieverBM25(BaseRetriever):\n",
    "    def __init__(self, bm25_retriever):\n",
    "        self.bm25_retriever = bm25_retriever\n",
    "        super().__init__()\n",
    "\n",
    "    def _retrieve(self, query, **kwargs):\n",
    "        bm25_nodes = self.bm25_retriever.retrieve(query, **kwargs)\n",
    "        all_nodes = []\n",
    "        node_ids = set()\n",
    "        for n in bm25_nodes:\n",
    "            if n.node.node_id not in node_ids:\n",
    "                all_nodes.append(n)\n",
    "                node_ids.add(n.node.node_id)\n",
    "        return all_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker = SentenceTransformerRerank(top_n=4, model=\"BAAI/bge-reranker-base\")\n",
    "\n",
    "# nodes retrieved by the bm25 retriever with the reranker\n",
    "reranked_nodes_bm25 = reranker.postprocess_nodes(\n",
    "    nodes_bm25_response,\n",
    "    query_bundle=QueryBundle(QUERY),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index, nodes, _ = get_index_and_nodes_from_activeloop(\n",
    "    vector_store_path=VECTOR_STORE_PATH_COMPLETE_SEQUENTIALLY\n",
    ")\n",
    "self.vector_retriever = index.as_retriever(similarity_top_k=2)\n",
    "self.bm25_retriever = BM25Retriever.from_defaults(\n",
    "    nodes=nodes, similarity_top_k=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranked_nodes_bm25 = self.reranker.postprocess_nodes(\n",
    "        self.nodes_bm25_response,\n",
    "        query_bundle=QueryBundle(QUERY),\n",
    "    )\n",
    "print(\"Reranked Nodes BM25\\n\\n\")\n",
    "for el in reranked_nodes_bm25:\n",
    "    print(f\"{el.score}\\n\")\n",
    "\n",
    "reranked_nodes_vector = self.reranker.postprocess_nodes(\n",
    "self.nodes_vector_response,\n",
    "query_bundle=QueryBundle(QUERY),\n",
    ")\n",
    "print(\"Reranked Nodes Vector\\n\\n\")\n",
    "for el in reranked_nodes_vector:\n",
    "    print(f\"{el.score}\\n\")\n",
    "    unique_nodes = keep_best_k_unique_nodes(\n",
    "        reranked_nodes_bm25, reranked_nodes_vector\n",
    "    )\n",
    "    print(\"Unique Nodes\\n\\n\")\n",
    "for el in unique_nodes:\n",
    "    print(f\"{el.id} : {el.score}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.retrievers import BM25Retriever\n",
    "\n",
    "vector_retriever = index.as_retriever(similarity_top_k=2)\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_defaults(\n",
    "    docstore=index.docstore, similarity_top_k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.retrievers import QueryFusionRetriever\n",
    "\n",
    "retriever = QueryFusionRetriever(\n",
    "    [vector_retriever, bm25_retriever],\n",
    "    similarity_top_k=2,\n",
    "    num_queries=4,  # set this to 1 to disable query generation\n",
    "    mode=\"reciprocal_rerank\",\n",
    "    use_async=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.retrieve(description)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
