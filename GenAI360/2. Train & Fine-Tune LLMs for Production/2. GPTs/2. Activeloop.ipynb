{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplake\n",
    "\n",
    "# env variable ACTIVELOOP_TOKEN must be set with your API token\n",
    "\n",
    "# create dataset on deeplake\n",
    "username = \"<YOUR_ACTIVELOOP_USERNAME>\"\n",
    "dataset_name = \"test_dataset\"\n",
    "ds = deeplake.dataset(f\"hub://{username}/{dataset_name}\")\n",
    "\n",
    "# create column text\n",
    "ds.create_tensor('text', htype=\"text\")\n",
    "\n",
    "# add some texts to the dataset\n",
    "texts = [f\"text {i}\" for i in range(1, 11)]\n",
    "for text in texts:\n",
    "    ds.append({\"text\": text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.commit(\"added texts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create PyTorch data loader\n",
    "batch_size = 3\n",
    "train_loader = ds.dataloader()\\\n",
    "    .batch(batch_size)\\\n",
    "    .shuffle()\\\n",
    "    .pytorch()\n",
    "\n",
    "# loop over the elements\n",
    "for i, batch in enumerate(train_loader):\n",
    "    print(f\"Batch {i}\")\n",
    "    samples = batch.get(\"text\")\n",
    "    for j, sample in enumerate(samples):\n",
    "        print(f\"Sample {j}: {sample}\")\n",
    "    print()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class DeepLakePyTorchDataset(Dataset):\n",
    "    def __init__(self, ds):\n",
    "        self.ds = ds\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        texts = self.ds.text[idx].text().astype(str)\n",
    "        return { \"text\": texts }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create PyTorch dataset\n",
    "ds_pt = DeepLakePyTorchDataset(ds)\n",
    "\n",
    "# create PyTorch data loader from PyTorch dataset\n",
    "dataloader_pytorch = DataLoader(ds_pt, batch_size=3, shuffle=True)\n",
    "\n",
    "# loop over the elements\n",
    "for i, batch in enumerate(dataloader_pytorch):\n",
    "    print(f\"Batch {i}\")\n",
    "    samples = batch.get(\"text\")\n",
    "    for j, sample in enumerate(samples):\n",
    "        print(f\"Sample {j}: {sample}\")\n",
    "    print()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_view = ds.query(\"select * where contains(text, '1')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_view.save_view(id=\"strings_with_1\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
