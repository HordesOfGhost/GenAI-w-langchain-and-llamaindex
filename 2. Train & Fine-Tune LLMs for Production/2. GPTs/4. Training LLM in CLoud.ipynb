{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import deeplake\n",
    "\n",
    "ds = deeplake.load('hub://activeloop/openwebtext-train')\n",
    "ds_val = deeplake.load('hub://activeloop/openwebtext-val')\n",
    "\n",
    "print(ds)\n",
    "print(ds[0].text.text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# define transform to tokenize texts\n",
    "def get_tokens_transform(tokenizer):\n",
    "    def tokens_transform(sample_in):\n",
    "        tokenized_text = tokenizer(\n",
    "            sample_in[\"text\"],\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        tokenized_text = tokenized_text[\"input_ids\"][0]\n",
    "        return {\n",
    "            \"input_ids\": tokenized_text,\n",
    "            \"labels\": tokenized_text\n",
    "        }\n",
    "    return tokens_transform\n",
    "\n",
    "# create data loaders\n",
    "ds_train_loader = ds.dataloader()\\\n",
    "    .batch(32)\\\n",
    "    .transform(get_tokens_transform(tokenizer))\\\n",
    "    .pytorch()\n",
    "ds_eval_train_loader = ds_val.dataloader()\\\n",
    "    .batch(32)\\\n",
    "    .transform(get_tokens_transform(tokenizer))\\\n",
    "    .pytorch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\"gpt2\")\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    GPT2Config {\n",
    "        \"_name_or_path\": \"gpt2\",\n",
    "        \"activation_function\": \"gelu_new\",\n",
    "        \"architectures\": [\n",
    "        \"GPT2LMHeadModel\"\n",
    "        ],\n",
    "        \"attn_pdrop\": 0.1,\n",
    "        \"bos_token_id\": 50256,\n",
    "        \"embd_pdrop\": 0.1,\n",
    "        \"eos_token_id\": 50256,\n",
    "        \"initializer_range\": 0.02,\n",
    "        \"layer_norm_epsilon\": 1e-05,\n",
    "        \"model_type\": \"gpt2\",\n",
    "        \"n_ctx\": 1024,\n",
    "        \"n_embd\": 768,\n",
    "        \"n_head\": 12,\n",
    "        \"n_inner\": null,\n",
    "        \"n_layer\": 12,\n",
    "        \"n_positions\": 1024,\n",
    "        \"reorder_and_upcast_attn\": false,\n",
    "        \"resid_pdrop\": 0.1,\n",
    "        \"scale_attn_by_inverse_layer_idx\": false,\n",
    "        \"scale_attn_weights\": true,\n",
    "        \"summary_activation\": null,\n",
    "        \"summary_first_dropout\": 0.1,\n",
    "        \"summary_proj_to_labels\": true,\n",
    "        \"summary_type\": \"cls_index\",\n",
    "        \"summary_use_proj\": true,\n",
    "        \"task_specific_params\": {\n",
    "        \"text-generation\": {\n",
    "        \"do_sample\": true,\n",
    "        \"max_length\": 50\n",
    "        }\n",
    "        },\n",
    "        \"transformers_version\": \"4.30.2\",\n",
    "        \"use_cache\": true,\n",
    "        \"vocab_size\": 50257\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "\n",
    "model = GPT2LMHeadModel(config)\n",
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "print(f\"GPT-2 size: {model_size/1e6:.1f}M parameters\")\n",
    "\n",
    "GPT2-1B size: 124.4M parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "config.n_layer = 32\n",
    "config.n_embd = 1600\n",
    "config.n_positions = 512\n",
    "config.n_ctx = 512\n",
    "config.n_head = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_1b = GPT2LMHeadModel(config)\n",
    "\n",
    "model_size = sum(t.numel() for t in model_1b.parameters())\n",
    "print(f\"GPT2-1B size: {model_size/1e6:.1f}M parameters\")\n",
    "\n",
    "GPT2-1B size: 1065.8M parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"GPT2-scratch-openwebtext\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    num_train_epochs=2,\n",
    "    logging_steps=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=100,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    bf16=True,\n",
    "    ddp_find_unused_parameters=False,\n",
    "    run_name=\"GPT2-scratch-openwebtext\",\n",
    "    report_to=\"wandb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "class TrainerWithDataLoaders(Trainer):\n",
    "    def __init__(self, *args, train_dataloader=None, eval_dataloader=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.eval_dataloader = eval_dataloader\n",
    "\n",
    "    def get_train_dataloader(self):\n",
    "        return self.train_dataloader\n",
    "\n",
    "    def get_eval_dataloader(self, dummy):\n",
    "        return self.eval_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "trainer = TrainerWithDataLoaders(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataloader=ds_train_loader,\n",
    "    eval_dataloader=ds_eval_train_loader,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\",\n",
    "                model=\"./GPT2-scratch-openwebtext\",\n",
    "                tokenizer=tokenizer,\n",
    "                device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "txt = \"The house prices dropped down\"\n",
    "\n",
    "completion = pipe(txt, num_return_sequences=1)\n",
    "print(completion)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
