{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import deeplake\n",
    "\n",
    "# Connect to the training and testing datasets\n",
    "ds = deeplake.load('hub://genai360/OpenOrca-1M-train-set')\n",
    "ds_valid = deeplake.load('hub://genai360/OpenOrca-1M-valid-set')\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Dataset(path='hub://genai360/OpenOrca-1M-train-set', read_only=True, tensors=['id', 'question', 'response', 'system_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_sample_text(example):\n",
    "    \"\"\"Prepare the text from a sample of the dataset.\"\"\"\n",
    "    text = f\"Question: {example['question'][0]}\\n\\nAnswer: {example['response'][0]}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-1.3b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from trl.trainer import ConstantLengthDataset\n",
    "\n",
    "train_dataset = ConstantLengthDataset(\n",
    "    tokenizer,\n",
    "    ds,\n",
    "    formatting_func=prepare_sample_text,\n",
    "    infinite=True,\n",
    "    seq_length=2048\n",
    ")\n",
    "\n",
    "eval_dataset = ConstantLengthDataset(\n",
    "    tokenizer,\n",
    "    ds_valid,\n",
    "    formatting_func=prepare_sample_text,\n",
    "    seq_length=1024\n",
    ")\n",
    "\n",
    "iterator = iter(train_dataset)\n",
    "sample = next(iterator)\n",
    "print(sample)\n",
    "\n",
    "train_dataset.start_iteration = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Model and Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./OPT-fine_tuned-OpenOrca\",\n",
    "    dataloader_drop_last=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    num_train_epochs=2,\n",
    "    eval_steps=2000,\n",
    "    save_steps=2000,\n",
    "    logging_steps=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=1e-4,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_steps=100,\n",
    "    gradient_accumulation_steps=1,\n",
    "    bf16=True,\n",
    "    weight_decay=0.05,\n",
    "    ddp_find_unused_parameters=False,\n",
    "    run_name=\"OPT-fine_tuned-OpenOrca\",\n",
    "    report_to=\"wandb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from accelerate import Accelerator\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "  \"facebook/opt-1.3b\",\n",
    "\tquantization_config=quantization_config,\n",
    "\tdevice_map={\"\": Accelerator().process_index}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = False\n",
    "  if param.ndim == 1:\n",
    "    param.data = param.data.to(torch.float32)\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model.enable_input_require_grads()\n",
    "\n",
    "class CastOutputToFloat(nn.Sequential):\n",
    "  def forward(self, x): return super().forward(x).to(torch.float32)\n",
    "model.lm_head = CastOutputToFloat(model.lm_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    peft_config=lora_config,\n",
    "    packing=True,\n",
    ")\n",
    "\n",
    "print(\"Training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "  \"facebook/opt-1.3b\", return_dict=True, torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "from peft import PeftModel\n",
    "\n",
    "# Load the Lora model\n",
    "model = PeftModel.from_pretrained(model, \"./OPT-fine_tuned-OpenOrca/<step>\")\n",
    "model.eval()\n",
    "\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "model.save_pretrained(\"./OPT-fine_tuned-OpenOrca/merged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Reward Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import deeplake\n",
    "\n",
    "ds = deeplake.load('hub://genai360/Anthropic-hh-rlhf-train-set')\n",
    "ds_valid = deeplake.load('hub://genai360/Anthropic-hh-rlhf-test-set')\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Dataset(path='hub://genai360/Anthropic-hh-rlhf-train-set', read_only=True, tensors=['chosen', 'rejected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "      chosen = self.dataset.chosen[idx].text()\n",
    "      rejected = self.dataset.rejected[idx].text()\n",
    "\n",
    "      tokenized_chosen = tokenizer(chosen, truncation=True, max_length=max_length, padding='max_length')\n",
    "      tokenized_rejected = tokenizer(rejected, truncation=True, max_length=max_length, padding='max_length')\n",
    "\n",
    "      formatted_input = {\n",
    "        \"input_ids_chosen\": tokenized_chosen[\"input_ids\"],\n",
    "        \"attention_mask_chosen\": tokenized_chosen[\"attention_mask\"],\n",
    "        \"input_ids_rejected\": tokenized_rejected[\"input_ids\"],\n",
    "        \"attention_mask_rejected\": tokenized_rejected[\"attention_mask\"],\n",
    "      }\n",
    "\n",
    "      return formatted_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(ds)\n",
    "eval_dataset = MyDataset(ds_valid)\n",
    "\n",
    "# Print one sample row\n",
    "iterator = iter(train_dataset)\n",
    "one_sample = next(iterator)\n",
    "print(list(one_sample.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Model and Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"microsoft/deberta-v3-base\", num_labels=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"DeBERTa-reward-hh_rlhf\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=24,\n",
    "    per_device_eval_batch_size=24,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.001,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    gradient_accumulation_steps=1,\n",
    "    bf16=True,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    optim=\"adamw_hf\",\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    ddp_find_unused_parameters=False,\n",
    "    run_name=\"DeBERTa-reward-hh_rlhf\",\n",
    "    report_to=\"wandb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from trl import RewardTrainer\n",
    "\n",
    "trainer = RewardTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    max_length=max_length\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import deeplake\n",
    "\n",
    "# Connect to the training and testing datasets\n",
    "ds = deeplake.load('hub://genai360/Alpaca-OrcaChat')\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Dataset(path='hub://genai360/Alpaca-OrcaChat', read_only=True, tensors=['input', 'instruction', 'output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-1.3b\", padding_side='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, ds):\n",
    "        self.ds = ds\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "      query = \"Question: \" + self.ds.input[idx].text() + \"\\n\\nAnswer: \"\n",
    "      tokenized_question = tokenizer(query, truncation=True, max_length=400, padding='max_length', return_tensors=\"pt\")\n",
    "\n",
    "      formatted_input = {\n",
    "        \"query\": query,\n",
    "        \"input_ids\": tokenized_question[\"input_ids\"][0],\n",
    "      }\n",
    "\n",
    "      return formatted_input\n",
    "\n",
    "# Define the dataset object\n",
    "myTrainingLoader = MyDataset(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize SIFT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from trl import PPOConfig\n",
    "\n",
    "config = PPOConfig(\n",
    "    task_name=\"OPT-RL-OrcaChat\",\n",
    "    steps=10_000,\n",
    "    model_name=\"./OPT-fine_tuned-OpenOrca/merged\",\n",
    "    learning_rate=1.41e-5,\n",
    "    batch_size=32,\n",
    "    mini_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optimize_cuda_cache=True,\n",
    "    early_stopping=False,\n",
    "    target_kl=0.1,\n",
    "    ppo_epochs=4,\n",
    "    seed=0,\n",
    "    init_kl_coef=0.2,\n",
    "    adap_kl_ctrl=True,\n",
    "    tracker_project_name=\"GenAI360\",\n",
    "    log_with=\"wandb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from trl import set_seed\n",
    "from accelerate import Accelerator\n",
    "\n",
    "# set seed before initializing value head for deterministic eval\n",
    "set_seed(config.seed)\n",
    "\n",
    "# Now let's build the model, the reference model, and the tokenizer.\n",
    "current_device = Accelerator().local_process_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "\n",
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(\n",
    "    config.model_name,\n",
    "    load_in_8bit=True,\n",
    "    device_map={\"\": current_device},\n",
    "    peft_config=lora_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Reward Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "reward_pipeline = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"./DeBERTa-v3-base-reward-hh_rlhf/checkpoint-1000\",\n",
    "    tokenizer=\"./DeBERTa-v3-base-reward-hh_rlhf/checkpoint-1000\",\n",
    "    device_map={\"\": current_device},\n",
    "    model_kwargs={\"load_in_8bit\": True},\n",
    "    return_token_type_ids=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from trl.core import LengthSampler\n",
    "\n",
    "output_length_sampler = LengthSampler(32, 400) #(OutputMinLength, OutputMaxLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sft_gen_kwargs = {\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.pad_token_id,\n",
    "    \"eos_token_id\": 100_000,\n",
    "}\n",
    "\n",
    "reward_gen_kwargs = {\n",
    "    \"top_k\": None,\n",
    "    \"function_to_apply\": \"none\",\n",
    "    \"batch_size\": 16,\n",
    "    \"truncation\": True,\n",
    "    \"max_length\": 400\n",
    "}\n",
    "\n",
    "save_freq = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from trl import PPOTrainer\n",
    "\n",
    "ppo_trainer = PPOTrainer(\n",
    "    config,\n",
    "    model,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset=myTrainingLoader,\n",
    "    data_collator=collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "for step, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    if step >= config.total_ppo_epochs:\n",
    "        break\n",
    "    question_tensors = batch[\"input_ids\"]\n",
    "\n",
    "    response_tensors = ppo_trainer.generate(\n",
    "        question_tensors,\n",
    "        return_prompt=False,\n",
    "        length_sampler=output_length_sampler,\n",
    "        **sft_gen_kwargs,\n",
    "    )\n",
    "    batch[\"response\"] = tokenizer.batch_decode(response_tensors, skip_special_tokens=True)\n",
    "\n",
    "    # Compute reward score\n",
    "    texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
    "    pipe_outputs = reward_pipeline(texts, **reward_gen_kwargs)\n",
    "\n",
    "    rewards = [torch.tensor(output[0][\"score\"]) for output in pipe_outputs]\n",
    "\n",
    "    # Run PPO step\n",
    "    stats = ppo_trainer.step(question_tensors, response_tensors, rewards)\n",
    "    ppo_trainer.log_stats(stats, batch, rewards)\n",
    "\n",
    "    if save_freq and step and step % save_freq == 0:\n",
    "        print(\"Saving checkpoint.\")\n",
    "        ppo_trainer.save_pretrained(f\"./OPT-RL-OrcaChat/checkpoint-{step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "  \"facebook/opt-1.3b\", return_dict=True, torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "from peft import PeftModel\n",
    "\n",
    "# Load the Lora model\n",
    "model = PeftModel.from_pretrained(model, \"./OPT-RL-OrcaChat/checkpoint-400/\")\n",
    "model.eval();\n",
    "\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "model.save_pretrained(\"./OPT-RL-OrcaChat/merged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QLORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "\tmodel_name_or_path='/name/or/path/to/your/model',\n",
    "\tload_in_4bit=True,\n",
    "\tdevice_map='auto',\n",
    "\ttorch_dtype=torch.bfloat16,\n",
    "\tquantization_config=BitsAndBytesConfig(\n",
    "\t\tload_in_4bit=True,\n",
    "\t\tbnb_4bit_compute_dtype=torch.bfloat16,\n",
    "\t\tbnb_4bit_use_double_quant=True,\n",
    "\t\tbnb_4bit_quant_type='nf4'\n",
    "\t),\n",
    "\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-1.3b\")\n",
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "from accelerate import Accelerator\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"./OPT-RL-OrcaChat/merged\", device_map={\"\": Accelerator().process_index}\n",
    ")\n",
    "model.eval();\n",
    "\n",
    "inputs = tokenizer(\"Question: In one sentence, describe what the following article is about:\\n\\nClick on “Store” along the menu toolbar at the upper left of the screen. Click on “Sign In” from the drop-down menu and enter your Apple ID and password. After logging in, click on “Store” on the toolbar again and select “View Account” from the drop-down menu. This will open the Account Information page.  Click on the drop-down list and select the country you want to change your iTunes Store to.  You’ll now be directed to the iTunes Store welcome page. Review the Terms and Conditions Agreement and click on “Agree” if you wish to proceed. Click on “Continue” once you’re done to complete changing your iTunes Store..\\n\\n Answer: \", return_tensors=\"pt\").to(\"cuda:0\")\n",
    "generation_output = model.generate(**inputs,\n",
    "                                   return_dict_in_generate=True,\n",
    "                                   output_scores=True,\n",
    "                                   max_new_tokens=128,\n",
    "                                   num_beams=4,\n",
    "                                   do_sample=True,\n",
    "                                   top_k=10,\n",
    "                                   temperature=0.6)\n",
    "print( tokenizer.decode(generation_output['sequences'][0]) )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
